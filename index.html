<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>streaming fastspeech</title>

  <meta property="og:type" content="website" />

  <link rel="stylesheet" href="https://latex.now.sh/style.min.css" />
  <style>
    body {max-width: 60%;}
    audio {
      max-width: 100%;
      max-height: 100%;
      box-sizing:border-box;
    }
    table tbody tr td {
      min-width: 170px;
      box-sizing:border-box;
    }
    table {
      max-width: 100%;
      border-top: 0px;
      border-bottom: 1.2px solid rgba(46, 46, 46, 0.253);
    }
    table tbody tr:last-child td {
      border-bottom: 0px;
    }
    table tbody tr:first-child td {
      border-top: 1.36px;
    }
    @media only screen and (max-width: 500px) {
      body {
        max-width: 100%;
      }
    }
    @media only screen and (min-width: 900px) {
      body {
        max-width: 60%;
      }
    }
    </style>
</head>

<body id="top" class="libertinus">
  <header role="banner">
    <h2 style="text-align: center;">
      How to make TTS system respond in milliseconds with any sentence length:
      <br>
      Non-autoregressive half-streaming model for low-resource devices
    </h2>
  </header>
  <p>
    <span style="font-weight: bold;">Abstract:</span> This paper deals with the problem of reducing the latency of the high-quality text-to-speech systems, when deploying on low-computing-resource devices.
    The FastStreamSpeech model was proposed, which combines the advantages of two recent advanced approaches in neural TTS: (1) the fast inference and robustness
    from the non-autoregressive approach and (2) the low and sentence-length independent latency from the streaming mechanism.
    A specific attention masking mechanism was proposed, allowing the streaming model can generate natural output, meanwhile it can only access a small part of the input sequence.
    This proposed model then was deployed and well evaluated on different platforms. Experimental result shows that: compared to the baseline non-streaming model,
    the proposed system can greatly speed up the system latency, while remain comparable speech output quality.
  </p>
  <main>
    <article>
      <header>
        <h2>Audio samples</h2>
      </header>
      <blockquote style="font-size:x-large">
        "Ngày mai không biết trời có mưa nhiều không hả anh , anh nhớ mang áo mưa đi nhé"
      </blockquote>
      <div class="scroll-wrapper">
        <table>
          <thead>
            <tr>
              <th style="text-align: center">Ground Truth</th>
              <th style="text-align: center">Baseline (no streaming)</th>
              <th style="text-align: center">Vocoder streaming only</th>
              <th style="text-align: center">Decoder-Vocoder streaming</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><audio controls src="./assets/audio/gt/COMPARE_005.wav" type="audio/wav">gt</audio></td>
              <td><audio controls src="./assets/audio/bl/COMPARE_005.wav" type="audio/wav">bl</audio></td>
              <td><audio controls src="./assets/audio/voc/COMPARE_005.wav" type="audio/wav">voc</audio></td>
              <td><audio controls src="./assets/audio/fs/COMPARE_005.wav" type="audio/wav">fs</audio></td>
            </tr>
          </tbody>
        </table>
      </div>
    </article>
  </main>

</body>

</html>